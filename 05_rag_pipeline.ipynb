{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0980127e",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a8e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e86d41",
   "metadata": {},
   "source": [
    "# RAG DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3961ef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage folders ready.\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"models\"\n",
    "EMBED_PATH = os.path.join(BASE_PATH, \"embedding_model\")\n",
    "\n",
    "os.makedirs(EMBED_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Storage folders ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0890a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded.\n",
      "Characters: 9832\n"
     ]
    }
   ],
   "source": [
    "PDF_PATH = \"rag/telecom_doc.pdf\"   \n",
    "\n",
    "\n",
    "def load_pdf(file_path):\n",
    "\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "\n",
    "        page_text = page.extract_text()\n",
    "\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "text_data = load_pdf(PDF_PATH)\n",
    "\n",
    "print(\"Document loaded.\")\n",
    "print(\"Characters:\", len(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4091eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_smart(text,\n",
    "                     chunk_size=300,\n",
    "                     overlap=50):\n",
    "\n",
    "    # Split into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        # If adding sentence stays within limit\n",
    "        if len(current_chunk) + len(sentence) <= chunk_size:\n",
    "\n",
    "            current_chunk += \" \" + sentence\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Save chunk\n",
    "            chunks.append(current_chunk.strip())\n",
    "\n",
    "            # Start new chunk with overlap\n",
    "            overlap_text = current_chunk[-overlap:]\n",
    "\n",
    "            current_chunk = overlap_text + \" \" + sentence\n",
    "\n",
    "    # Add last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb8b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 36\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_text_smart(text_data,\n",
    "                          chunk_size=300,\n",
    "                          overlap=50)\n",
    "\n",
    "print(\"Total chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead591f",
   "metadata": {},
   "source": [
    "# EMBEDDING MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 666.07it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model saved offline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embedding_model.save(EMBED_PATH)\n",
    "\n",
    "print(\"Embedding model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41afdcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (36, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(chunks)\n",
    "\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f46f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created.\n"
     ]
    }
   ],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8113885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG model saved using joblib.\n"
     ]
    }
   ],
   "source": [
    "rag_artifacts = {\n",
    "    \"faiss_index\": index,\n",
    "    \"chunks\": chunks\n",
    "}\n",
    "\n",
    "joblib.dump(rag_artifacts, \"models/rag_artifacts.pkl\")\n",
    "\n",
    "print(\"RAG model saved \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d4992",
   "metadata": {},
   "source": [
    "# RAG EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee0b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, top_k=3):\n",
    "\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
    "\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0b6d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pany Policies\n",
      "Billing: Monthly billing in advance. Enterprise customers receive consolidated invoices. Late payment after 7\n",
      "days may suspend services.\n",
      "Refund:  Full  refund  within  7  days  if  usage  is  less  than  10%.\n",
      "within  7  days  if  usage  is  less  than  10%. Cloud  services  are  non-refundable  after\n",
      "activation.\n",
      "3\n",
      "Contracts: Individual users have no long-term lock-in.\n",
      "racts: Individual users have no long-term lock-in. Enterprise customers have a minimum 12-month\n",
      "contract.\n",
      "SLA: Individual users have 98.5% uptime, business users 99.5% uptime, and enterprise users 99.9% uptime.\n",
      "Data Privacy: GDPR compliant, ISO 27001 certified, and encrypted data at rest and in transit.\n",
      "Fair Usage: Unlimited plans are capped at 1TB per month.\n",
      "Support Tiers: Standard, Priority, and Enterprise Dedicated Support.\n",
      "Discounts: Bulk enterprise users can receive up to 30% discount.\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_context(\"What is the refund policy?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
